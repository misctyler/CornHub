{"cells":[{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" == Request Token == \n","    * oauth_token        = xflYnKShWsPiedZgOOgKgrZcOMQxqjEHKnIqwSnx\n","    * oauth_token_secret = sALaBeDhqYjMiDkDfDGOYEegUdRVyQeRBUZEeOUH\n","\n","Please browse to the following URL https://www.discogs.com/oauth/authorize?oauth_token=xflYnKShWsPiedZgOOgKgrZcOMQxqjEHKnIqwSnx\n","\n"," == Access Token ==\n","    * oauth_token        = mVwHQbCqiKdBUWMTwwAKRpxIztrgqntADsKjmnBe\n","    * oauth_token_secret = lnqIqazCbaajQNvXKAWNptEYvZJNbuQrJGKSPjLj\n"," Authentication complete. Future requests must be signed with the above tokens.\n","\n","\n","== Search results for release_title= Deft Ones, Artist= Commodo ==\n"," == API image request ==\n","    * response status      = 200\n","    * saving image to disk = anBn.jpeg\n"]}],"source":["import pandas as pd\n","from textblob import TextBlob\n","import numpy as np\n","from datetime import datetime\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","import sklearn.metrics as m\n","from sklearn.preprocessing import OneHotEncoder\n","import nltk, sys, json\n","import discogs_client\n","from urllib import request\n","from urllib.parse import parse_qsl\n","from urllib.parse import urlparse\n","import oauth2 as oauth\n","\n","data = pd.read_csv('Record-Collection.csv')\n","consumer_key = 'FdxaljOTWBmKXCysYsQZ'\n","consumer_secret = 'lrfQIsgQonpeUnEuLWRpJgWKLdhKMaYe'\n","request_token_url = 'https://api.discogs.com/oauth/request_token'\n","authorize_url = 'https://www.discogs.com/oauth/authorize'\n","access_token_url = 'https://api.discogs.com/oauth/access_token'\n","user_agent = 'discogs_api_example/1.0'\n","consumer = oauth.Consumer(consumer_key, consumer_secret)\n","client = oauth.Client(consumer)\n","resp, content = client.request(request_token_url, 'POST', headers={'User-Agent': user_agent})\n","if resp['status'] != '200':\n","    sys.exit('Invalid response {0}.'.format(resp['status']))\n","request_token = dict(parse_qsl(content.decode('utf-8')))\n","\n","print(' == Request Token == ')\n","print(f'    * oauth_token        = {request_token[\"oauth_token\"]}')\n","print(f'    * oauth_token_secret = {request_token[\"oauth_token_secret\"]}')\n","print()\n","print(f'Please browse to the following URL {authorize_url}?oauth_token={request_token[\"oauth_token\"]}')\n","\n","# Waiting for user input\n","accepted = 'n'\n","while accepted.lower() == 'n':\n","    print()\n","    accepted = input(f'Have you authorized me at {authorize_url}?oauth_token={request_token[\"oauth_token\"]} [y/n] :')\n","oauth_verifier = input('Verification code : ')\n","\n","# Generate objects that pass the verification key with the oauth token and oauth\n","# secret to the discogs access_token_url\n","token = oauth.Token(request_token['oauth_token'], request_token['oauth_token_secret'])\n","token.set_verifier(oauth_verifier)\n","client = oauth.Client(consumer, token)\n","\n","resp, content = client.request(access_token_url, 'POST', headers={'User-Agent': user_agent})\n","access_token = dict(parse_qsl(content.decode('utf-8')))\n","\n","print(' == Access Token ==')\n","print(f'    * oauth_token        = {access_token[\"oauth_token\"]}')\n","print(f'    * oauth_token_secret = {access_token[\"oauth_token_secret\"]}')\n","print(' Authentication complete. Future requests must be signed with the above tokens.')\n","print()\n","\n","token = oauth.Token(key=access_token['oauth_token'],\n","        secret=access_token['oauth_token_secret'])\n","client = oauth.Client(consumer, token)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","== Search results for release_title= Brood VII, Artist= Jade Cicada ==\n","\n","\t== discogs-id 17109261 ==\n","\tTitle\t: Jade Cicada - Brood VII\n","\tYear\t: 2017\n","\tLabels\t: Swarm Audio\n","\tCat No\t: none\n","\tFormats\t: Vinyl, 12\", 45 RPM, Album, Compilation\n","\n","\t== discogs-id 15522483 ==\n","\tTitle\t: Jade Cicada - Brood VII\n","\tYear\t: 2017\n","\tLabels\t: Swarm Audio\n","\tCat No\t: none\n","\tFormats\t: File, AAC, AIFF, FLAC, MP3, WAV, Album, Vinyl, LP, Limited Edition\n"," == API image request ==\n","    * response status      = 200\n","    * saving image to disk = anBn.jpeg\n"]}],"source":["# With an active auth token, we're able to reuse the client object and request\n","# additional discogs authenticated endpoints, such as database search.\n","\n","artist_ = 'Jade Cicada'\n","title_ = 'Brood VII'\n","\n","resp, content = client.request('https://api.discogs.com/database/search?release_title='+title_.replace(\" \",'+')+'&artist='+artist_.replace(\" \",'+'),\n","        headers={'User-Agent': user_agent})\n","\n","if resp['status'] != '200':\n","    sys.exit('Invalid API response {0}.'.format(resp['status']))\n","\n","releases = json.loads(content.decode('utf-8'))\n","print('\\n== Search results for release_title= ' + title_ + ', Artist= ' + artist_ + ' ==')\n","for release in releases['results']:\n","    print(f'\\n\\t== discogs-id {release[\"id\"]} ==')\n","    print(f'\\tTitle\\t: {release.get(\"title\", \"Unknown\")}')\n","    print(f'\\tYear\\t: {release.get(\"year\", \"Unknown\")}')\n","    print(f'\\tLabels\\t: {\", \".join(release.get(\"label\", [\"Unknown\"]))}')\n","    print(f'\\tCat No\\t: {release.get(\"catno\", \"Unknown\")}')\n","    print(f'\\tFormats\\t: {\", \".join(release.get(\"format\", [\"Unknown\"]))}')\n","\n","resp, content = client.request('https://api.discogs.com/releases/40522',\n","        headers={'User-Agent': user_agent})\n","\n","if resp['status'] != '200':\n","    sys.exit('Unable to fetch release 40522')\n","\n","# load the JSON response content into a dictionary.\n","release = json.loads(content.decode('utf-8'))\n","# extract the first image uri.\n","image = release['images'][0]['uri']\n","\n","# The authenticated URL is generated for you. There is no longer a need to\n","# wrap the image download request in an OAuth signature.\n","# build, send the HTTP GET request for the desired image.\n","# DOCS: http://www.discogs.com/forum/thread/410594\n","try:\n","    request.urlretrieve(image, image.split('/')[-1])\n","except Exception as e:\n","    sys.exit(f'Unable to download image {image}, error {e}')\n","\n","print(' == API image request ==')\n","print(f'    * response status      = {resp[\"status\"]}')\n","print(f'    * saving image to disk = {image.split(\"/\")[-1]}')\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","case_num, description, sentiment_score, polarity_score, type, subtype, rating, dates = [], [], [], [], [], [], [], []\n","complaint_type_ , MSE_LR, MSE_XGB, R2_LR, R2_XGB = [], [], [], [], []\n","x = 0\n","while x < len(data):\n","    description_x = str(data.iat[x,data.columns.get_loc('Description of the Problem/Request')]).strip()\n","    type_x = str(data.iat[x,data.columns.get_loc('Concern Type')]).strip()\n","    subtype_x = str(data.iat[x,data.columns.get_loc('Concern Sub-Type')]).strip()\n","    case_num_x = str(data.iat[x,data.columns.get_loc('Case Number')]).strip()\n","    sentiment_score_x = TextBlob(description_x).sentiment.subjectivity    \n","    polarity_score_x = TextBlob(description_x).sentiment.polarity    \n","    sentiment_category = [1 if sentiment_score_x > 0                      \n","                          else -1 if sentiment_score_x < 0                        \n","                          else 0]\n","    case_num.append(case_num_x)\n","    description.append(description_x)\n","    sentiment_score.append(sentiment_score_x)\n","    polarity_score.append(polarity_score_x)\n","    rating.append(sentiment_category)\n","    type.append(type_x)\n","    subtype.append(subtype_x)\n","    dates.append(data.iat[x,data.columns.get_loc('Opened Date')])\n","    x = x + 1\n","# pre process data for training model\n","day_of_week = [datetime.strptime(str(date), '%Y-%m-%d %H:%M:%S').weekday() for date in dates]\n","results = {  'Case Number': case_num  \n","            ,'Day of Week' : day_of_week  \n","            ,'Type': type          \n","            ,'Sub-Type': subtype          \n","            ,'Description': description          \n","            ,'Sentiment': sentiment_score          \n","            ,'Polarity': polarity_score          \n","            ,'Rating Score': rating\n","            }\n","\n","pre_results_df = pd.DataFrame(results)\n","encoder = OneHotEncoder(handle_unknown='ignore')\n","x_encoded = encoder.fit_transform(pre_results_df['Type'].values.reshape(-1,1))\n","x_encoded_df = pd.DataFrame(x_encoded.toarray(), columns=encoder.get_feature_names_out(['Type']))\n","encoded_df = pd.concat([pre_results_df, x_encoded_df], axis=1)\n","encoded_df = encoded_df.drop(['Type'], axis=1)\n","x_encoded = encoder.fit_transform(encoded_df['Day of Week'].values.reshape(-1,1))\n","x_encoded_df = pd.DataFrame(x_encoded.toarray(), columns=encoder.get_feature_names_out(['Day of Week']))\n","encoded_df = pd.concat([encoded_df, x_encoded_df], axis=1)\n","encoded_df = encoded_df.drop(['Day of Week'], axis=1)\n","complaint_types = encoded_df.columns.tolist()\n","\n","# create training and testing models for each complaint type\n","x = 6\n","while x < len(complaint_types):\n","    complaint_type_.append(complaint_types[x])\n","    # split complaint data into training / test sets    \n","    features = [complaint_types[x], 'Sentiment' ]\n","    target = \"Polarity\"\n","    x_train, x_test, y_train, y_test = train_test_split(encoded_df[features], encoded_df[target], test_size=0.3, random_state=0)\n","\n","    # train the prediction models    \n","    regressor = LinearRegression()\n","    x_regressor = XGBRegressor(random_state=42)\n","    y_train = y_train.values.reshape(-1,1)\n","    regressor.fit(x_train, y_train)\n","    x_regressor.fit(x_train,y_train)\n","\n","    # make prediction using test data    \n","    M_pred = regressor.predict(x_test)\n","    X_pred = x_regressor.predict(x_test)\n","\n","    # evaluate model performance    \n","    mse = m.mean_squared_error(y_test, M_pred)\n","    R2_ = m.r2_score(y_test,M_pred)\n","    MSE_LR.append(mse)\n","    R2_LR.append(R2_)\n","    mse_ = m.mean_squared_error(y_test,X_pred)\n","    MSE_XGB.append(mse_)\n","    R2__ = m.r2_score(y_test,X_pred)\n","    R2_XGB.append(R2__)\n","    x = x + 1\n","\n","trained_results = { 'Complaint Type' : complaint_type_\n","                  ,'MSE LR' : MSE_LR\n","                  ,'R2 LR': R2_LR\n","                  ,'MSE X' : MSE_XGB\n","                  ,'R2 X' : R2_XGB                  \n","                  }\n","\n","trained_results_df = pd.DataFrame(trained_results)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":2}
